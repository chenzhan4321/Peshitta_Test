{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('s2-in.txt', sep='\\t')\n",
    "df.head()\n",
    "text_combined = df['Text'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary v. 1.0, maybe unnecessary? 完全不必要，用Keras的Tokenizer就行了\n",
    "vocab = {}\n",
    "i = 1\n",
    "\n",
    "for word in text_combined.split():\n",
    "    if word in vocab:\n",
    "        continue\n",
    "    else:\n",
    "        vocab[word]=i\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WMLK>',\n",
       " 'DWJD',\n",
       " 'S>B',\n",
       " 'W<L',\n",
       " 'BC\"NJ>',\n",
       " 'WMKSJN',\n",
       " 'HWW',\n",
       " 'LH',\n",
       " 'BLBWC\">',\n",
       " 'WL>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separator v. 1.0\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "tokens = tokenize(text_combined)\n",
    "len(tokens)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize into sequences of tokens\n",
    "train_len = 25+1 # 25 training words , then one target word\n",
    "\n",
    "# Empty list of sequences\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    \n",
    "    # Grab train_len# amount of characters\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    # Add to list of sequences\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mfit_on_texts(text_sequences)\n\u001b[1;32m      8\u001b[0m sequences \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(text_sequences)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mindex_word[:\u001b[38;5;241m10\u001b[39m]) \u001b[38;5;66;03m#index_word is a dictionary where keys are indices and values are words\u001b[39;00m\n\u001b[1;32m     10\u001b[0m vocabulary_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mword_index) \u001b[38;5;66;03m#总共有多少词形\u001b[39;00m\n\u001b[1;32m     11\u001b[0m vocabulary_size\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "# Tokenize the sequences\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(lower=False) #ETCBC data is in uppercase, we need to keep it that way\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
    "print(tokenizer.index_word[:10]) #index_word is a dictionary where keys are indices and values are words\n",
    "vocabulary_size = len(tokenizer.word_index) #总共有多少词形\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sequences = np.array(sequences) #converts the Python list into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77974, 18035)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formalize the data and labels. The data will be all the words in the sequence except the last one, and the label will be the last word in the sequence.\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X = sequences[:,:-1] #all rows, all columns except the last one\n",
    "y = sequences[:,-1] #all rows, last column only\n",
    "y_one_hot = to_categorical(y, num_classes=vocabulary_size+1) #one-hot encoding\n",
    "seq_len = X.shape[1]\n",
    "y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 23:58:08.668734: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-03-30 23:58:08.810199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-30 23:58:08.810927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-30 23:58:08.811486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 25)            450875    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 25, 50)            15200     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 18035)             919785    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,408,610\n",
      "Trainable params: 1,408,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 23:58:08.893274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-30 23:58:08.894108: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-30 23:58:08.894661: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "def creat_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = creat_model(vocabulary_size+1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 23:58:11.132511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-30 23:58:11.133524: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-30 23:58:11.134215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-30 23:58:11.231548: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-30 23:58:11.232293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-30 23:58:11.232993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-30 23:58:11.694758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-30 23:58:11.695708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-30 23:58:11.696433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-30 23:58:11.792787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-30 23:58:11.793555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-30 23:58:11.794316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 17s 26ms/step - loss: 8.6057 - accuracy: 0.0213\n",
      "Epoch 2/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 8.1861 - accuracy: 0.0220\n",
      "Epoch 3/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 8.0568 - accuracy: 0.0233\n",
      "Epoch 4/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 7.8946 - accuracy: 0.0241\n",
      "Epoch 5/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 7.7003 - accuracy: 0.0264\n",
      "Epoch 6/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 7.5109 - accuracy: 0.0280\n",
      "Epoch 7/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 7.3404 - accuracy: 0.0317\n",
      "Epoch 8/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 7.1697 - accuracy: 0.0351\n",
      "Epoch 9/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 6.9982 - accuracy: 0.0402\n",
      "Epoch 10/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 6.8251 - accuracy: 0.0451\n",
      "Epoch 11/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 6.6569 - accuracy: 0.0501\n",
      "Epoch 12/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 6.4985 - accuracy: 0.0547\n",
      "Epoch 13/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 6.3465 - accuracy: 0.0595\n",
      "Epoch 14/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 6.2014 - accuracy: 0.0640\n",
      "Epoch 15/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 6.0616 - accuracy: 0.0682\n",
      "Epoch 16/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 5.9264 - accuracy: 0.0722\n",
      "Epoch 17/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 5.7929 - accuracy: 0.0773\n",
      "Epoch 18/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 5.6592 - accuracy: 0.0823\n",
      "Epoch 19/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 5.5275 - accuracy: 0.0874\n",
      "Epoch 20/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 5.4001 - accuracy: 0.0931\n",
      "Epoch 21/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 5.2766 - accuracy: 0.0981\n",
      "Epoch 22/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 5.1501 - accuracy: 0.1047\n",
      "Epoch 23/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 5.0296 - accuracy: 0.1111\n",
      "Epoch 24/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 4.9129 - accuracy: 0.1190\n",
      "Epoch 25/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 4.8007 - accuracy: 0.1279\n",
      "Epoch 26/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 4.6935 - accuracy: 0.1361\n",
      "Epoch 27/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 4.5837 - accuracy: 0.1461\n",
      "Epoch 28/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 4.4832 - accuracy: 0.1560\n",
      "Epoch 29/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 4.3897 - accuracy: 0.1673\n",
      "Epoch 30/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 4.3019 - accuracy: 0.1776\n",
      "Epoch 31/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 4.2150 - accuracy: 0.1887\n",
      "Epoch 32/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 4.1366 - accuracy: 0.1985\n",
      "Epoch 33/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 4.0614 - accuracy: 0.2070\n",
      "Epoch 34/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.9911 - accuracy: 0.2182\n",
      "Epoch 35/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.9218 - accuracy: 0.2250\n",
      "Epoch 36/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.8576 - accuracy: 0.2361\n",
      "Epoch 37/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.8033 - accuracy: 0.2437\n",
      "Epoch 38/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.7442 - accuracy: 0.2510\n",
      "Epoch 39/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 3.6836 - accuracy: 0.2599\n",
      "Epoch 40/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 3.6337 - accuracy: 0.2691\n",
      "Epoch 41/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 3.5779 - accuracy: 0.2757\n",
      "Epoch 42/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 3.5285 - accuracy: 0.2835\n",
      "Epoch 43/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.4790 - accuracy: 0.2920\n",
      "Epoch 44/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.4264 - accuracy: 0.2987\n",
      "Epoch 45/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.3841 - accuracy: 0.3060\n",
      "Epoch 46/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 3.3411 - accuracy: 0.3149\n",
      "Epoch 47/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 3.2961 - accuracy: 0.3198\n",
      "Epoch 48/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.2504 - accuracy: 0.3289\n",
      "Epoch 49/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.2064 - accuracy: 0.3343\n",
      "Epoch 50/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.1658 - accuracy: 0.3427\n",
      "Epoch 51/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 3.1236 - accuracy: 0.3494\n",
      "Epoch 52/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 3.0926 - accuracy: 0.3537\n",
      "Epoch 53/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 3.0487 - accuracy: 0.3597\n",
      "Epoch 54/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 3.0139 - accuracy: 0.3669\n",
      "Epoch 55/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 2.9772 - accuracy: 0.3727\n",
      "Epoch 56/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.9440 - accuracy: 0.3788\n",
      "Epoch 57/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.9009 - accuracy: 0.3855\n",
      "Epoch 58/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.8747 - accuracy: 0.3911\n",
      "Epoch 59/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.8395 - accuracy: 0.3976\n",
      "Epoch 60/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.8034 - accuracy: 0.4027\n",
      "Epoch 61/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.7725 - accuracy: 0.4093\n",
      "Epoch 62/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.7322 - accuracy: 0.4164\n",
      "Epoch 63/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.7041 - accuracy: 0.4199\n",
      "Epoch 64/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 2.6776 - accuracy: 0.4264\n",
      "Epoch 65/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.6448 - accuracy: 0.4317\n",
      "Epoch 66/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.6141 - accuracy: 0.4363\n",
      "Epoch 67/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.5831 - accuracy: 0.4435\n",
      "Epoch 68/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 2.5611 - accuracy: 0.4480\n",
      "Epoch 69/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.5328 - accuracy: 0.4514\n",
      "Epoch 70/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.5038 - accuracy: 0.4569\n",
      "Epoch 71/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 2.4762 - accuracy: 0.4627\n",
      "Epoch 72/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.4498 - accuracy: 0.4670\n",
      "Epoch 73/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.4252 - accuracy: 0.4731\n",
      "Epoch 74/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.3955 - accuracy: 0.4780\n",
      "Epoch 75/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.3661 - accuracy: 0.4829\n",
      "Epoch 76/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.3442 - accuracy: 0.4871\n",
      "Epoch 77/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.3171 - accuracy: 0.4924\n",
      "Epoch 78/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 2.2975 - accuracy: 0.4957\n",
      "Epoch 79/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 2.2797 - accuracy: 0.4991\n",
      "Epoch 80/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.2489 - accuracy: 0.5063\n",
      "Epoch 81/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.2177 - accuracy: 0.5104\n",
      "Epoch 82/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.1940 - accuracy: 0.5155\n",
      "Epoch 83/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 2.1814 - accuracy: 0.5185\n",
      "Epoch 84/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.1582 - accuracy: 0.5228\n",
      "Epoch 85/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.1322 - accuracy: 0.5267\n",
      "Epoch 86/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 2.1021 - accuracy: 0.5339\n",
      "Epoch 87/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.0856 - accuracy: 0.5378\n",
      "Epoch 88/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.0627 - accuracy: 0.5414\n",
      "Epoch 89/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 2.0547 - accuracy: 0.5422\n",
      "Epoch 90/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 2.0258 - accuracy: 0.5481\n",
      "Epoch 91/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 2.0051 - accuracy: 0.5520\n",
      "Epoch 92/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 1.9845 - accuracy: 0.5561\n",
      "Epoch 93/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.9677 - accuracy: 0.5597\n",
      "Epoch 94/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.9372 - accuracy: 0.5669\n",
      "Epoch 95/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 1.9158 - accuracy: 0.5707\n",
      "Epoch 96/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.9054 - accuracy: 0.5720\n",
      "Epoch 97/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.8985 - accuracy: 0.5723\n",
      "Epoch 98/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.8731 - accuracy: 0.5777\n",
      "Epoch 99/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 1.8464 - accuracy: 0.5831\n",
      "Epoch 100/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 1.8288 - accuracy: 0.5875\n",
      "Epoch 101/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.8244 - accuracy: 0.5871\n",
      "Epoch 102/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.8055 - accuracy: 0.5914\n",
      "Epoch 103/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.7822 - accuracy: 0.5972\n",
      "Epoch 104/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.7600 - accuracy: 0.6023\n",
      "Epoch 105/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 1.7501 - accuracy: 0.6039\n",
      "Epoch 106/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 1.7329 - accuracy: 0.6053\n",
      "Epoch 107/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.7159 - accuracy: 0.6104\n",
      "Epoch 108/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.7040 - accuracy: 0.6121\n",
      "Epoch 109/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 1.6972 - accuracy: 0.6124\n",
      "Epoch 110/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.6724 - accuracy: 0.6171\n",
      "Epoch 111/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.6612 - accuracy: 0.6205\n",
      "Epoch 112/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.6402 - accuracy: 0.6252\n",
      "Epoch 113/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.6211 - accuracy: 0.6297\n",
      "Epoch 114/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.6123 - accuracy: 0.6311\n",
      "Epoch 115/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.6089 - accuracy: 0.6324\n",
      "Epoch 116/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.5814 - accuracy: 0.6379\n",
      "Epoch 117/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.5739 - accuracy: 0.6390\n",
      "Epoch 118/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.5569 - accuracy: 0.6428\n",
      "Epoch 119/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.5396 - accuracy: 0.6467\n",
      "Epoch 120/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.5338 - accuracy: 0.6480\n",
      "Epoch 121/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.5151 - accuracy: 0.6515\n",
      "Epoch 122/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.4988 - accuracy: 0.6538\n",
      "Epoch 123/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.4878 - accuracy: 0.6561\n",
      "Epoch 124/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.4765 - accuracy: 0.6601\n",
      "Epoch 125/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.4675 - accuracy: 0.6621\n",
      "Epoch 126/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 1.4519 - accuracy: 0.6639\n",
      "Epoch 127/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.4283 - accuracy: 0.6688\n",
      "Epoch 128/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.4288 - accuracy: 0.6686\n",
      "Epoch 129/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.4208 - accuracy: 0.6707\n",
      "Epoch 130/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.3994 - accuracy: 0.6749\n",
      "Epoch 131/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.3787 - accuracy: 0.6801\n",
      "Epoch 132/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.3696 - accuracy: 0.6818\n",
      "Epoch 133/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.3681 - accuracy: 0.6817\n",
      "Epoch 134/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.3595 - accuracy: 0.6831\n",
      "Epoch 135/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.3429 - accuracy: 0.6863\n",
      "Epoch 136/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.3241 - accuracy: 0.6909\n",
      "Epoch 137/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.3097 - accuracy: 0.6945\n",
      "Epoch 138/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.3042 - accuracy: 0.6961\n",
      "Epoch 139/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.3022 - accuracy: 0.6953\n",
      "Epoch 140/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.3013 - accuracy: 0.6952\n",
      "Epoch 141/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.2833 - accuracy: 0.6987\n",
      "Epoch 142/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.2588 - accuracy: 0.7061\n",
      "Epoch 143/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.2367 - accuracy: 0.7107\n",
      "Epoch 144/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.2391 - accuracy: 0.7093\n",
      "Epoch 145/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.2290 - accuracy: 0.7109\n",
      "Epoch 146/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 1.2278 - accuracy: 0.7105\n",
      "Epoch 147/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.2067 - accuracy: 0.7162\n",
      "Epoch 148/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.1997 - accuracy: 0.7181\n",
      "Epoch 149/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.1886 - accuracy: 0.7207\n",
      "Epoch 150/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.1795 - accuracy: 0.7218\n",
      "Epoch 151/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.1735 - accuracy: 0.7248\n",
      "Epoch 152/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.1545 - accuracy: 0.7277\n",
      "Epoch 153/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.1532 - accuracy: 0.7276\n",
      "Epoch 154/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.1380 - accuracy: 0.7324\n",
      "Epoch 155/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.1349 - accuracy: 0.7313\n",
      "Epoch 156/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.1250 - accuracy: 0.7339\n",
      "Epoch 157/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.1283 - accuracy: 0.7325\n",
      "Epoch 158/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.1117 - accuracy: 0.7363\n",
      "Epoch 159/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.0938 - accuracy: 0.7417\n",
      "Epoch 160/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.0766 - accuracy: 0.7466\n",
      "Epoch 161/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.0763 - accuracy: 0.7451\n",
      "Epoch 162/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 1.0772 - accuracy: 0.7437\n",
      "Epoch 163/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.0694 - accuracy: 0.7448\n",
      "Epoch 164/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.0605 - accuracy: 0.7480\n",
      "Epoch 165/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.0455 - accuracy: 0.7506\n",
      "Epoch 166/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 1.0437 - accuracy: 0.7510\n",
      "Epoch 167/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 1.0266 - accuracy: 0.7573\n",
      "Epoch 168/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.0193 - accuracy: 0.7573\n",
      "Epoch 169/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 1.0125 - accuracy: 0.7589\n",
      "Epoch 170/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.9981 - accuracy: 0.7620\n",
      "Epoch 171/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.9950 - accuracy: 0.7613\n",
      "Epoch 172/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.9895 - accuracy: 0.7647\n",
      "Epoch 173/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.9948 - accuracy: 0.7621\n",
      "Epoch 174/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.9746 - accuracy: 0.7689\n",
      "Epoch 175/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.9545 - accuracy: 0.7719\n",
      "Epoch 176/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.9543 - accuracy: 0.7717\n",
      "Epoch 177/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.9410 - accuracy: 0.7749\n",
      "Epoch 178/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.9430 - accuracy: 0.7732\n",
      "Epoch 179/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.9322 - accuracy: 0.7772\n",
      "Epoch 180/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.9297 - accuracy: 0.7761\n",
      "Epoch 181/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.9279 - accuracy: 0.7774\n",
      "Epoch 182/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.9222 - accuracy: 0.7780\n",
      "Epoch 183/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.9094 - accuracy: 0.7828\n",
      "Epoch 184/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.8820 - accuracy: 0.7883\n",
      "Epoch 185/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.8851 - accuracy: 0.7862\n",
      "Epoch 186/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.8799 - accuracy: 0.7894\n",
      "Epoch 187/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.8724 - accuracy: 0.7901\n",
      "Epoch 188/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.8750 - accuracy: 0.7883\n",
      "Epoch 189/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.8668 - accuracy: 0.7913\n",
      "Epoch 190/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.8505 - accuracy: 0.7951\n",
      "Epoch 191/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.8391 - accuracy: 0.7984\n",
      "Epoch 192/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.8393 - accuracy: 0.7979\n",
      "Epoch 193/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.8435 - accuracy: 0.7958\n",
      "Epoch 194/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.8420 - accuracy: 0.7969\n",
      "Epoch 195/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.8180 - accuracy: 0.8029\n",
      "Epoch 196/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.8020 - accuracy: 0.8067\n",
      "Epoch 197/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7849 - accuracy: 0.8102\n",
      "Epoch 198/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.7978 - accuracy: 0.8064\n",
      "Epoch 199/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.8006 - accuracy: 0.8048\n",
      "Epoch 200/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.7873 - accuracy: 0.8082\n",
      "Epoch 201/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7852 - accuracy: 0.8093\n",
      "Epoch 202/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7734 - accuracy: 0.8123\n",
      "Epoch 203/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7614 - accuracy: 0.8158\n",
      "Epoch 204/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7556 - accuracy: 0.8157\n",
      "Epoch 205/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.7494 - accuracy: 0.8166\n",
      "Epoch 206/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7372 - accuracy: 0.8211\n",
      "Epoch 207/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7445 - accuracy: 0.8196\n",
      "Epoch 208/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.7441 - accuracy: 0.8185\n",
      "Epoch 209/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7327 - accuracy: 0.8214\n",
      "Epoch 210/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7312 - accuracy: 0.8204\n",
      "Epoch 211/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.7218 - accuracy: 0.8241\n",
      "Epoch 212/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.6996 - accuracy: 0.8298\n",
      "Epoch 213/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7024 - accuracy: 0.8285\n",
      "Epoch 214/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.7038 - accuracy: 0.8284\n",
      "Epoch 215/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6822 - accuracy: 0.8337\n",
      "Epoch 216/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6929 - accuracy: 0.8309\n",
      "Epoch 217/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.6834 - accuracy: 0.8324\n",
      "Epoch 218/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6739 - accuracy: 0.8353\n",
      "Epoch 219/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6613 - accuracy: 0.8395\n",
      "Epoch 220/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6639 - accuracy: 0.8376\n",
      "Epoch 221/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6746 - accuracy: 0.8346\n",
      "Epoch 222/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6655 - accuracy: 0.8364\n",
      "Epoch 223/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6472 - accuracy: 0.8413\n",
      "Epoch 224/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6447 - accuracy: 0.8418\n",
      "Epoch 225/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6388 - accuracy: 0.8438\n",
      "Epoch 226/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6345 - accuracy: 0.8432\n",
      "Epoch 227/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6231 - accuracy: 0.8468\n",
      "Epoch 228/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6288 - accuracy: 0.8446\n",
      "Epoch 229/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.6350 - accuracy: 0.8431\n",
      "Epoch 230/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.6324 - accuracy: 0.8430\n",
      "Epoch 231/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6119 - accuracy: 0.8497\n",
      "Epoch 232/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5970 - accuracy: 0.8530\n",
      "Epoch 233/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.5959 - accuracy: 0.8533\n",
      "Epoch 234/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6013 - accuracy: 0.8514\n",
      "Epoch 235/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5962 - accuracy: 0.8529\n",
      "Epoch 236/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5960 - accuracy: 0.8530\n",
      "Epoch 237/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.6009 - accuracy: 0.8518\n",
      "Epoch 238/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5827 - accuracy: 0.8563\n",
      "Epoch 239/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5713 - accuracy: 0.8577\n",
      "Epoch 240/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5677 - accuracy: 0.8601\n",
      "Epoch 241/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5696 - accuracy: 0.8593\n",
      "Epoch 242/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5548 - accuracy: 0.8630\n",
      "Epoch 243/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5669 - accuracy: 0.8596\n",
      "Epoch 244/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5690 - accuracy: 0.8590\n",
      "Epoch 245/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5720 - accuracy: 0.8581\n",
      "Epoch 246/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5665 - accuracy: 0.8606\n",
      "Epoch 247/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5516 - accuracy: 0.8624\n",
      "Epoch 248/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5243 - accuracy: 0.8705\n",
      "Epoch 249/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.5415 - accuracy: 0.8675\n",
      "Epoch 250/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.5376 - accuracy: 0.8673\n",
      "Epoch 251/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5287 - accuracy: 0.8689\n",
      "Epoch 252/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5299 - accuracy: 0.8685\n",
      "Epoch 253/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5258 - accuracy: 0.8695\n",
      "Epoch 254/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5161 - accuracy: 0.8727\n",
      "Epoch 255/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.5099 - accuracy: 0.8737\n",
      "Epoch 256/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5208 - accuracy: 0.8697\n",
      "Epoch 257/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5334 - accuracy: 0.8664\n",
      "Epoch 258/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.5086 - accuracy: 0.8729\n",
      "Epoch 259/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4908 - accuracy: 0.8793\n",
      "Epoch 260/500\n",
      "610/610 [==============================] - 17s 27ms/step - loss: 0.4736 - accuracy: 0.8829\n",
      "Epoch 261/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4967 - accuracy: 0.8761\n",
      "Epoch 262/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4988 - accuracy: 0.8753\n",
      "Epoch 263/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.5275 - accuracy: 0.8672\n",
      "Epoch 264/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4869 - accuracy: 0.8786\n",
      "Epoch 265/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4598 - accuracy: 0.8867\n",
      "Epoch 266/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4792 - accuracy: 0.8826\n",
      "Epoch 267/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4818 - accuracy: 0.8811\n",
      "Epoch 268/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4872 - accuracy: 0.8772\n",
      "Epoch 269/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4749 - accuracy: 0.8807\n",
      "Epoch 270/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4584 - accuracy: 0.8858\n",
      "Epoch 271/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.4632 - accuracy: 0.8857\n",
      "Epoch 272/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4653 - accuracy: 0.8843\n",
      "Epoch 273/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4459 - accuracy: 0.8912\n",
      "Epoch 274/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4480 - accuracy: 0.8876\n",
      "Epoch 275/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4562 - accuracy: 0.8850\n",
      "Epoch 276/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4602 - accuracy: 0.8839\n",
      "Epoch 277/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.4471 - accuracy: 0.8875\n",
      "Epoch 278/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.4348 - accuracy: 0.8909\n",
      "Epoch 279/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4238 - accuracy: 0.8937\n",
      "Epoch 280/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4319 - accuracy: 0.8923\n",
      "Epoch 281/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4406 - accuracy: 0.8902\n",
      "Epoch 282/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4389 - accuracy: 0.8886\n",
      "Epoch 283/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4283 - accuracy: 0.8926\n",
      "Epoch 284/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4339 - accuracy: 0.8914\n",
      "Epoch 285/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4171 - accuracy: 0.8957\n",
      "Epoch 286/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4010 - accuracy: 0.8997\n",
      "Epoch 287/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4204 - accuracy: 0.8950\n",
      "Epoch 288/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.4136 - accuracy: 0.8962\n",
      "Epoch 289/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4213 - accuracy: 0.8930\n",
      "Epoch 290/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4360 - accuracy: 0.8905\n",
      "Epoch 291/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4088 - accuracy: 0.8979\n",
      "Epoch 292/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.3780 - accuracy: 0.9053\n",
      "Epoch 293/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3859 - accuracy: 0.9035\n",
      "Epoch 294/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3941 - accuracy: 0.9011\n",
      "Epoch 295/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4062 - accuracy: 0.8968\n",
      "Epoch 296/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3867 - accuracy: 0.9038\n",
      "Epoch 297/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3989 - accuracy: 0.8996\n",
      "Epoch 298/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.4062 - accuracy: 0.8978\n",
      "Epoch 299/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3920 - accuracy: 0.9018\n",
      "Epoch 300/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3837 - accuracy: 0.9029\n",
      "Epoch 301/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.3875 - accuracy: 0.9024\n",
      "Epoch 302/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3712 - accuracy: 0.9071\n",
      "Epoch 303/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3677 - accuracy: 0.9086\n",
      "Epoch 304/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3683 - accuracy: 0.9061\n",
      "Epoch 305/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3724 - accuracy: 0.9063\n",
      "Epoch 306/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3720 - accuracy: 0.9061\n",
      "Epoch 307/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.3678 - accuracy: 0.9067\n",
      "Epoch 308/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.3641 - accuracy: 0.9060\n",
      "Epoch 309/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3725 - accuracy: 0.9061\n",
      "Epoch 310/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3495 - accuracy: 0.9121\n",
      "Epoch 311/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.3555 - accuracy: 0.9103\n",
      "Epoch 312/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.3713 - accuracy: 0.9057\n",
      "Epoch 313/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3595 - accuracy: 0.9081\n",
      "Epoch 314/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3633 - accuracy: 0.9072\n",
      "Epoch 315/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3465 - accuracy: 0.9117\n",
      "Epoch 316/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3339 - accuracy: 0.9165\n",
      "Epoch 317/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.3435 - accuracy: 0.9133\n",
      "Epoch 318/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.3298 - accuracy: 0.9165\n",
      "Epoch 319/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3369 - accuracy: 0.9141\n",
      "Epoch 320/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3395 - accuracy: 0.9138\n",
      "Epoch 321/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.3628 - accuracy: 0.9081\n",
      "Epoch 322/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3414 - accuracy: 0.9126\n",
      "Epoch 323/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.3273 - accuracy: 0.9183\n",
      "Epoch 324/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.3210 - accuracy: 0.9189\n",
      "Epoch 325/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3291 - accuracy: 0.9174\n",
      "Epoch 326/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3413 - accuracy: 0.9148\n",
      "Epoch 327/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3264 - accuracy: 0.9178\n",
      "Epoch 328/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3233 - accuracy: 0.9183\n",
      "Epoch 329/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3265 - accuracy: 0.9171\n",
      "Epoch 330/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3272 - accuracy: 0.9169\n",
      "Epoch 331/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3305 - accuracy: 0.9157\n",
      "Epoch 332/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3209 - accuracy: 0.9186\n",
      "Epoch 333/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.3035 - accuracy: 0.9233\n",
      "Epoch 334/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.3006 - accuracy: 0.9254\n",
      "Epoch 335/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2919 - accuracy: 0.9270\n",
      "Epoch 336/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3188 - accuracy: 0.9184\n",
      "Epoch 337/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.3291 - accuracy: 0.9160\n",
      "Epoch 338/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3261 - accuracy: 0.9155\n",
      "Epoch 339/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.3024 - accuracy: 0.9248\n",
      "Epoch 340/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2987 - accuracy: 0.9245\n",
      "Epoch 341/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.2856 - accuracy: 0.9275\n",
      "Epoch 342/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2992 - accuracy: 0.9224\n",
      "Epoch 343/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3030 - accuracy: 0.9215\n",
      "Epoch 344/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2974 - accuracy: 0.9245\n",
      "Epoch 345/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3024 - accuracy: 0.9232\n",
      "Epoch 346/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3025 - accuracy: 0.9232\n",
      "Epoch 347/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2826 - accuracy: 0.9284\n",
      "Epoch 348/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2780 - accuracy: 0.9291\n",
      "Epoch 349/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2961 - accuracy: 0.9248\n",
      "Epoch 350/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3155 - accuracy: 0.9181\n",
      "Epoch 351/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2902 - accuracy: 0.9255\n",
      "Epoch 352/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2827 - accuracy: 0.9282\n",
      "Epoch 353/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2842 - accuracy: 0.9284\n",
      "Epoch 354/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2820 - accuracy: 0.9287\n",
      "Epoch 355/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2898 - accuracy: 0.9261\n",
      "Epoch 356/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2792 - accuracy: 0.9291\n",
      "Epoch 357/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2721 - accuracy: 0.9305\n",
      "Epoch 358/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2719 - accuracy: 0.9305\n",
      "Epoch 359/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2685 - accuracy: 0.9309\n",
      "Epoch 360/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2631 - accuracy: 0.9333\n",
      "Epoch 361/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2821 - accuracy: 0.9272\n",
      "Epoch 362/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2964 - accuracy: 0.9248\n",
      "Epoch 363/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.3181 - accuracy: 0.9176\n",
      "Epoch 364/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2520 - accuracy: 0.9359\n",
      "Epoch 365/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2531 - accuracy: 0.9372\n",
      "Epoch 366/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2445 - accuracy: 0.9389\n",
      "Epoch 367/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.2692 - accuracy: 0.9308\n",
      "Epoch 368/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2696 - accuracy: 0.9309\n",
      "Epoch 369/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2618 - accuracy: 0.9324\n",
      "Epoch 370/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2568 - accuracy: 0.9334\n",
      "Epoch 371/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2491 - accuracy: 0.9357\n",
      "Epoch 372/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2429 - accuracy: 0.9364\n",
      "Epoch 373/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2542 - accuracy: 0.9339\n",
      "Epoch 374/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.2547 - accuracy: 0.9350\n",
      "Epoch 375/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2593 - accuracy: 0.9332\n",
      "Epoch 376/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2576 - accuracy: 0.9338\n",
      "Epoch 377/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2582 - accuracy: 0.9331\n",
      "Epoch 378/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2656 - accuracy: 0.9313\n",
      "Epoch 379/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2501 - accuracy: 0.9358\n",
      "Epoch 380/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2396 - accuracy: 0.9388\n",
      "Epoch 381/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2513 - accuracy: 0.9355\n",
      "Epoch 382/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2503 - accuracy: 0.9351\n",
      "Epoch 383/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2273 - accuracy: 0.9424\n",
      "Epoch 384/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.2278 - accuracy: 0.9417\n",
      "Epoch 385/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2420 - accuracy: 0.9384\n",
      "Epoch 386/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2597 - accuracy: 0.9330\n",
      "Epoch 387/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2399 - accuracy: 0.9382\n",
      "Epoch 388/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2492 - accuracy: 0.9354\n",
      "Epoch 389/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2298 - accuracy: 0.9414\n",
      "Epoch 390/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2178 - accuracy: 0.9446\n",
      "Epoch 391/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2505 - accuracy: 0.9349\n",
      "Epoch 392/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.2623 - accuracy: 0.9337\n",
      "Epoch 393/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2377 - accuracy: 0.9384\n",
      "Epoch 394/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2209 - accuracy: 0.9436\n",
      "Epoch 395/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.2243 - accuracy: 0.9425\n",
      "Epoch 396/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2262 - accuracy: 0.9427\n",
      "Epoch 397/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2248 - accuracy: 0.9430\n",
      "Epoch 398/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.2176 - accuracy: 0.9441\n",
      "Epoch 399/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2366 - accuracy: 0.9397\n",
      "Epoch 400/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.2289 - accuracy: 0.9406\n",
      "Epoch 401/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2254 - accuracy: 0.9422\n",
      "Epoch 402/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2330 - accuracy: 0.9413\n",
      "Epoch 403/500\n",
      "610/610 [==============================] - 16s 25ms/step - loss: 0.2259 - accuracy: 0.9426\n",
      "Epoch 404/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2097 - accuracy: 0.9464\n",
      "Epoch 405/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2196 - accuracy: 0.9436\n",
      "Epoch 406/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2297 - accuracy: 0.9414\n",
      "Epoch 407/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2463 - accuracy: 0.9363\n",
      "Epoch 408/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2180 - accuracy: 0.9444\n",
      "Epoch 409/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2000 - accuracy: 0.9497\n",
      "Epoch 410/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2073 - accuracy: 0.9468\n",
      "Epoch 411/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2023 - accuracy: 0.9492\n",
      "Epoch 412/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2186 - accuracy: 0.9433\n",
      "Epoch 413/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.2290 - accuracy: 0.9414\n",
      "Epoch 414/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2292 - accuracy: 0.9404\n",
      "Epoch 415/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2110 - accuracy: 0.9464\n",
      "Epoch 416/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2129 - accuracy: 0.9454\n",
      "Epoch 417/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.2000 - accuracy: 0.9485\n",
      "Epoch 418/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.1931 - accuracy: 0.9501\n",
      "Epoch 419/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.1968 - accuracy: 0.9484\n",
      "Epoch 420/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2098 - accuracy: 0.9459\n",
      "Epoch 421/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2210 - accuracy: 0.9422\n",
      "Epoch 422/500\n",
      "610/610 [==============================] - 14s 24ms/step - loss: 0.2087 - accuracy: 0.9463\n",
      "Epoch 423/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2136 - accuracy: 0.9450\n",
      "Epoch 424/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1984 - accuracy: 0.9494\n",
      "Epoch 425/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1947 - accuracy: 0.9500\n",
      "Epoch 426/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2018 - accuracy: 0.9480\n",
      "Epoch 427/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2065 - accuracy: 0.9460\n",
      "Epoch 428/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2108 - accuracy: 0.9458\n",
      "Epoch 429/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1995 - accuracy: 0.9480\n",
      "Epoch 430/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2103 - accuracy: 0.9462\n",
      "Epoch 431/500\n",
      "610/610 [==============================] - 14s 24ms/step - loss: 0.2083 - accuracy: 0.9462\n",
      "Epoch 432/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2003 - accuracy: 0.9478\n",
      "Epoch 433/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2003 - accuracy: 0.9483\n",
      "Epoch 434/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1911 - accuracy: 0.9514\n",
      "Epoch 435/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1935 - accuracy: 0.9496\n",
      "Epoch 436/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1908 - accuracy: 0.9514\n",
      "Epoch 437/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1892 - accuracy: 0.9511\n",
      "Epoch 438/500\n",
      "610/610 [==============================] - 14s 24ms/step - loss: 0.2055 - accuracy: 0.9468\n",
      "Epoch 439/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1855 - accuracy: 0.9518\n",
      "Epoch 440/500\n",
      "610/610 [==============================] - 14s 24ms/step - loss: 0.1789 - accuracy: 0.9549\n",
      "Epoch 441/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1879 - accuracy: 0.9515\n",
      "Epoch 442/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1921 - accuracy: 0.9506\n",
      "Epoch 443/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2050 - accuracy: 0.9478\n",
      "Epoch 444/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2006 - accuracy: 0.9474\n",
      "Epoch 445/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1841 - accuracy: 0.9528\n",
      "Epoch 446/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1594 - accuracy: 0.9590\n",
      "Epoch 447/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1717 - accuracy: 0.9568\n",
      "Epoch 448/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1960 - accuracy: 0.9500\n",
      "Epoch 449/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2032 - accuracy: 0.9464\n",
      "Epoch 450/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1973 - accuracy: 0.9495\n",
      "Epoch 451/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1838 - accuracy: 0.9524\n",
      "Epoch 452/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1709 - accuracy: 0.9567\n",
      "Epoch 453/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.1781 - accuracy: 0.9540\n",
      "Epoch 454/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.1917 - accuracy: 0.9503\n",
      "Epoch 455/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.1900 - accuracy: 0.9501\n",
      "Epoch 456/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.1778 - accuracy: 0.9538\n",
      "Epoch 457/500\n",
      "610/610 [==============================] - 16s 26ms/step - loss: 0.1598 - accuracy: 0.9591\n",
      "Epoch 458/500\n",
      "610/610 [==============================] - 16s 27ms/step - loss: 0.1774 - accuracy: 0.9540\n",
      "Epoch 459/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.1959 - accuracy: 0.9486\n",
      "Epoch 460/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.1903 - accuracy: 0.9507\n",
      "Epoch 461/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.1591 - accuracy: 0.9589\n",
      "Epoch 462/500\n",
      "610/610 [==============================] - 15s 25ms/step - loss: 0.1621 - accuracy: 0.9594\n",
      "Epoch 463/500\n",
      "610/610 [==============================] - 14s 24ms/step - loss: 0.1714 - accuracy: 0.9562\n",
      "Epoch 464/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1818 - accuracy: 0.9533\n",
      "Epoch 465/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1889 - accuracy: 0.9507\n",
      "Epoch 466/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1888 - accuracy: 0.9505\n",
      "Epoch 467/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1665 - accuracy: 0.9575\n",
      "Epoch 468/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1706 - accuracy: 0.9556\n",
      "Epoch 469/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1681 - accuracy: 0.9576\n",
      "Epoch 470/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1705 - accuracy: 0.9563\n",
      "Epoch 471/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1666 - accuracy: 0.9563\n",
      "Epoch 472/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1691 - accuracy: 0.9563\n",
      "Epoch 473/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1864 - accuracy: 0.9509\n",
      "Epoch 474/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1986 - accuracy: 0.9490\n",
      "Epoch 475/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1704 - accuracy: 0.9571\n",
      "Epoch 476/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1413 - accuracy: 0.9638\n",
      "Epoch 477/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1331 - accuracy: 0.9653\n",
      "Epoch 478/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1529 - accuracy: 0.9606\n",
      "Epoch 479/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1841 - accuracy: 0.9523\n",
      "Epoch 480/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1889 - accuracy: 0.9498\n",
      "Epoch 481/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1864 - accuracy: 0.9521\n",
      "Epoch 482/500\n",
      "610/610 [==============================] - 14s 24ms/step - loss: 0.1628 - accuracy: 0.9581\n",
      "Epoch 483/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1470 - accuracy: 0.9619\n",
      "Epoch 484/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1630 - accuracy: 0.9572\n",
      "Epoch 485/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1562 - accuracy: 0.9599\n",
      "Epoch 486/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1738 - accuracy: 0.9556\n",
      "Epoch 487/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1979 - accuracy: 0.9495\n",
      "Epoch 488/500\n",
      "610/610 [==============================] - 14s 24ms/step - loss: 0.1763 - accuracy: 0.9549\n",
      "Epoch 489/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1637 - accuracy: 0.9587\n",
      "Epoch 490/500\n",
      "610/610 [==============================] - 14s 24ms/step - loss: 0.1362 - accuracy: 0.9663\n",
      "Epoch 491/500\n",
      "610/610 [==============================] - 14s 24ms/step - loss: 0.1310 - accuracy: 0.9668\n",
      "Epoch 492/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1732 - accuracy: 0.9545\n",
      "Epoch 493/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1716 - accuracy: 0.9557\n",
      "Epoch 494/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1655 - accuracy: 0.9569\n",
      "Epoch 495/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1761 - accuracy: 0.9542\n",
      "Epoch 496/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1533 - accuracy: 0.9601\n",
      "Epoch 497/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1367 - accuracy: 0.9645\n",
      "Epoch 498/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1406 - accuracy: 0.9651\n",
      "Epoch 499/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.1743 - accuracy: 0.9543\n",
      "Epoch 500/500\n",
      "610/610 [==============================] - 15s 24ms/step - loss: 0.2026 - accuracy: 0.9473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x772028316690>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pickle import dump, load\n",
    "model.fit(X, y_one_hot, batch_size=128, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms2-out.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m dump(tokenizer, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms2-out\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('s2-out.h5')\n",
    "dump(tokenizer, open('s2-out', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from pickle import load\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    model : model that was trained on text data\n",
    "    tokenizer : tokenizer that was fit on text data\n",
    "    seq_len : length of training sequence\n",
    "    seed_text : raw string text to serve as the seed\n",
    "    num_gen_words : number of words to be generated by model\n",
    "    '''\n",
    "    \n",
    "    # Final Output\n",
    "    output_text = []\n",
    "    \n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        # Pad sequences to our trained rate (50 words in the video)\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        # Predict class probabilities for each word\n",
    "        pred_probabilities = model.predict(pad_encoded, verbose=0)[0]\n",
    "\n",
    "        # Get the index of the word with the highest probability\n",
    "        pred_word_ind = np.argmax(pred_probabilities)\n",
    "        \n",
    "        # Grab word\n",
    "        pred_word = tokenizer.index_word[pred_word_ind] \n",
    "        \n",
    "        # Update the sequence of input text (shifting one over with the new word)\n",
    "        input_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    # Make it look like a sentence.\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 08:28:00.416074: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-31 08:28:00.416683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-31 08:28:00.417400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-31 08:28:00.500557: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-31 08:28:00.501287: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-31 08:28:00.501869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-31 08:28:00.659393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-31 08:28:00.660158: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-31 08:28:00.660771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-31 08:28:00.751183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-31 08:28:00.751997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-31 08:28:00.752609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LJV MN DKTJB WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "seed_text = \"DNTL LK >R<> DMRDJ> XLB> WDBC> CM< >JSRJL MRJ> >LHN MRJ> XD HW RXM LMRJ> >LHK MN KLH LBK WMN KLH^ NPCK WMN KLH QNJNK\"\n",
    "\n",
    "len(seed_text.split())\n",
    "model = load_model('s2-out.h5')\n",
    "tokenizer = load(open('s2-out', 'rb'))\n",
    "\n",
    "generate_text(model,tokenizer,seq_len=25,seed_text=seed_text,num_gen_words=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
