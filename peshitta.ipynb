{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('s2-in.txt', sep='\\t')\n",
    "df.head()\n",
    "text_combined = df['Text'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary v. 1.0, maybe unnecessary? 完全不必要，用Keras的Tokenizer就行了\n",
    "vocab = {}\n",
    "i = 1\n",
    "\n",
    "for word in text_combined.split():\n",
    "    if word in vocab:\n",
    "        continue\n",
    "    else:\n",
    "        vocab[word]=i\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WMLK>',\n",
       " 'DWJD',\n",
       " 'S>B',\n",
       " 'W<L',\n",
       " 'BC\"NJ>',\n",
       " 'WMKSJN',\n",
       " 'HWW',\n",
       " 'LH',\n",
       " 'BLBWC\">',\n",
       " 'WL>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separator v. 1.0\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "tokens = tokenize(text_combined)\n",
    "len(tokens)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize into sequences of tokens\n",
    "train_len = 25+1 # 25 training words , then one target word\n",
    "\n",
    "# Empty list of sequences\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    \n",
    "    # Grab train_len# amount of characters\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    # Add to list of sequences\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18034"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the sequences\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(lower=False) #ETCBC data is in uppercase, we need to keep it that way\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
    "vocabulary_size = len(tokenizer.word_index) #总共有多少词形\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sequences = np.array(sequences) #converts the Python list into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formalize the data and labels. The data will be all the words in the sequence except the last one, and the label will be the last word in the sequence.\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X = sequences[:,:-1] #all rows, all columns except the last one\n",
    "y = sequences[:,-1] #all rows, last column only\n",
    "y_one_hot = to_categorical(y, num_classes=vocabulary_size+1) #one-hot encoding\n",
    "seq_len = X.shape[1]\n",
    "y_one_hot.shape\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "def creat_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = creat_model(vocabulary_size+1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 03:12:10.747418: W external/local_tsl/tsl/framework/bfc_allocator.cc:487] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.24GiB (rounded to 5625044480)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-04-04 03:12:10.747495: I external/local_tsl/tsl/framework/bfc_allocator.cc:1044] BFCAllocator dump for GPU_0_bfc\n",
      "2024-04-04 03:12:10.747520: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (256): \tTotal Chunks: 24, Chunks in use: 24. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 328B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747535: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747548: I external/"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dump, load\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, y_one_hot, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (1024): \tTotal Chunks: 4, Chunks in use: 4. 4.2KiB allocated for chunks. 4.2KiB in use in bin. 3.3KiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747560: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747571: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747586: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (8192): \tTotal Chunks: 2, Chunks in use: 2. 20.0KiB allocated for chunks. 20.0KiB in use in bin. 19.5KiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747600: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (16384): \tTotal Chunks: 2, Chunks in use: 2. 39.5KiB allocated for chunks. 39.5KiB in use in bin. 39.1KiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747614: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (32768): \tTotal Chunks: 4, Chunks in use: 4. 157.0KiB allocated for chunks. 157.0KiB in use in bin. 156.2KiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747627: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (65536): \tTotal Chunks: 2, Chunks in use: 1. 175.0KiB allocated for chunks. 70.5KiB in use in bin. 70.4KiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747638: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747649: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747660: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747672: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 2. 3.44MiB allocated for chunks. 3.44MiB in use in bin. 3.44MiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747685: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (2097152): \tTotal Chunks: 2, Chunks in use: 2. 6.88MiB allocated for chunks. 6.88MiB in use in bin. 6.88MiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747695: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747710: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (8388608): \tTotal Chunks: 2, Chunks in use: 1. 23.72MiB allocated for chunks. 14.87MiB in use in bin. 14.87MiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747723: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 19.42MiB allocated for chunks. 19.42MiB in use in bin. 14.87MiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747742: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747753: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747763: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747776: I external/local_tsl/tsl/framework/bfc_allocator.cc:1051] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 1. 9.92GiB allocated for chunks. 5.25GiB in use in bin. 5.24GiB client-requested in use in bin.\n",
      "2024-04-04 03:12:10.747788: I external/local_tsl/tsl/framework/bfc_allocator.cc:1067] Bin for 5.24GiB was 256.00MiB, Chunk State: \n",
      "2024-04-04 03:12:10.747810: I external/local_tsl/tsl/framework/bfc_allocator.cc:1073]   Size: 4.66GiB | Requested Size: 60.2KiB | in_use: 0 | bin_num: 20, prev:   Size: 14.87MiB | Requested Size: 14.87MiB | in_use: 1 | bin_num: -1\n",
      "2024-04-04 03:12:10.747819: I external/local_tsl/tsl/framework/bfc_allocator.cc:1080] Next region of size 10705502208\n",
      "2024-04-04 03:12:10.747833: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000000 of size 256 next 1\n",
      "2024-04-04 03:12:10.747843: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000100 of size 1280 next 2\n",
      "2024-04-04 03:12:10.747852: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000600 of size 256 next 3\n",
      "2024-04-04 03:12:10.747860: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000700 of size 256 next 4\n",
      "2024-04-04 03:12:10.747868: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000800 of size 256 next 5\n",
      "2024-04-04 03:12:10.747877: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000900 of size 256 next 6\n",
      "2024-04-04 03:12:10.747885: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000a00 of size 256 next 87\n",
      "2024-04-04 03:12:10.747894: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000b00 of size 256 next 8\n",
      "2024-04-04 03:12:10.747902: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000c00 of size 256 next 9\n",
      "2024-04-04 03:12:10.747912: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 72166c000d00 of size 5640639488 next 11\n",
      "2024-04-04 03:12:10.747921: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bc356100 of size 256 next 12\n",
      "2024-04-04 03:12:10.747930: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bc356200 of size 256 next 13\n",
      "2024-04-04 03:12:10.747938: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bc356300 of size 256 next 83\n",
      "2024-04-04 03:12:10.747947: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bc356400 of size 256 next 44\n",
      "2024-04-04 03:12:10.747955: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bc356500 of size 256 next 59\n",
      "2024-04-04 03:12:10.747964: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bc356600 of size 20366080 next 46\n",
      "2024-04-04 03:12:10.747973: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bd6c2900 of size 256 next 48\n",
      "2024-04-04 03:12:10.747982: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bd6c2a00 of size 20224 next 79\n",
      "2024-04-04 03:12:10.747991: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bd6c7900 of size 1803520 next 58\n",
      "2024-04-04 03:12:10.748001: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bd87fe00 of size 20224 next 70\n",
      "2024-04-04 03:12:10.748011: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bd884d00 of size 40192 next 81\n",
      "2024-04-04 03:12:10.748021: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bd88ea00 of size 40192 next 72\n",
      "2024-04-04 03:12:10.748030: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bd898700 of size 1024 next 37\n",
      "2024-04-04 03:12:10.748041: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bd898b00 of size 10240 next 78\n",
      "2024-04-04 03:12:10.748052: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bd89b300 of size 3607040 next 65\n",
      "2024-04-04 03:12:10.748062: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bdc0bd00 of size 72192 next 76\n",
      "2024-04-04 03:12:10.748071: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bdc1d700 of size 40192 next 57\n",
      "2024-04-04 03:12:10.748079: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bdc27400 of size 40192 next 75\n",
      "2024-04-04 03:12:10.748088: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bdc31100 of size 1024 next 45\n",
      "2024-04-04 03:12:10.748097: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bdc31500 of size 10240 next 47\n",
      "2024-04-04 03:12:10.748105: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bdc33d00 of size 3607040 next 71\n",
      "2024-04-04 03:12:10.748114: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bdfa4700 of size 1803520 next 43\n",
      "2024-04-04 03:12:10.748122: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217be15cc00 of size 256 next 68\n",
      "2024-04-04 03:12:10.748131: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217be15cd00 of size 256 next 100\n",
      "2024-04-04 03:12:10.748139: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217be15ce00 of size 256 next 101\n",
      "2024-04-04 03:12:10.748148: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217be15cf00 of size 256 next 41\n",
      "2024-04-04 03:12:10.748156: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217be15d000 of size 256 next 42\n",
      "2024-04-04 03:12:10.748164: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217be15d100 of size 256 next 10\n",
      "2024-04-04 03:12:10.748173: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217be15d200 of size 256 next 89\n",
      "2024-04-04 03:12:10.748181: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217be15d300 of size 1024 next 88\n",
      "2024-04-04 03:12:10.748190: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217be15d700 of size 256 next 66\n",
      "2024-04-04 03:12:10.748198: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] Free  at 7217be15d800 of size 9281792 next 82\n",
      "2024-04-04 03:12:10.748207: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bea37900 of size 256 next 64\n",
      "2024-04-04 03:12:10.748216: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] Free  at 7217bea37a00 of size 107008 next 30\n",
      "2024-04-04 03:12:10.748224: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bea51c00 of size 256 next 29\n",
      "2024-04-04 03:12:10.748233: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] InUse at 7217bea51d00 of size 15595008 next 55\n",
      "2024-04-04 03:12:10.748243: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100] Free  at 7217bf931300 of size 5008387328 next 18446744073709551615\n",
      "2024-04-04 03:12:10.748252: I external/local_tsl/tsl/framework/bfc_allocator.cc:1105]      Summary of in-use Chunks by size: \n",
      "2024-04-04 03:12:10.748264: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 24 Chunks of size 256 totalling 6.0KiB\n",
      "2024-04-04 03:12:10.748274: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 3 Chunks of size 1024 totalling 3.0KiB\n",
      "2024-04-04 03:12:10.748284: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-04-04 03:12:10.748296: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 2 Chunks of size 10240 totalling 20.0KiB\n",
      "2024-04-04 03:12:10.748306: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 2 Chunks of size 20224 totalling 39.5KiB\n",
      "2024-04-04 03:12:10.748316: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 4 Chunks of size 40192 totalling 157.0KiB\n",
      "2024-04-04 03:12:10.748326: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 1 Chunks of size 72192 totalling 70.5KiB\n",
      "2024-04-04 03:12:10.748336: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 2 Chunks of size 1803520 totalling 3.44MiB\n",
      "2024-04-04 03:12:10.748345: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 2 Chunks of size 3607040 totalling 6.88MiB\n",
      "2024-04-04 03:12:10.748355: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 1 Chunks of size 15595008 totalling 14.87MiB\n",
      "2024-04-04 03:12:10.748365: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 1 Chunks of size 20366080 totalling 19.42MiB\n",
      "2024-04-04 03:12:10.748375: I external/local_tsl/tsl/framework/bfc_allocator.cc:1108] 1 Chunks of size 5640639488 totalling 5.25GiB\n",
      "2024-04-04 03:12:10.748385: I external/local_tsl/tsl/framework/bfc_allocator.cc:1112] Sum Total of in-use chunks: 5.30GiB\n",
      "2024-04-04 03:12:10.748395: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Total bytes in pool: 10705502208 memory_limit_: 10705502208 available bytes: 0 curr_region_allocation_bytes_: 21411004416\n",
      "2024-04-04 03:12:10.748412: I external/local_tsl/tsl/framework/bfc_allocator.cc:1119] Stats: \n",
      "Limit:                     10705502208\n",
      "InUse:                      5687726080\n",
      "MaxInUse:                   5748724992\n",
      "NumAllocs:                         548\n",
      "MaxAllocSize:               5640639488\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-04-04 03:12:10.748428: W external/local_tsl/tsl/framework/bfc_allocator.cc:499] ******************************************************______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump, load\n",
    "model.fit(X, y_one_hot, batch_size=128, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms2-out.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m dump(tokenizer, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms2-out\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('s2-out.h5')\n",
    "dump(tokenizer, open('s2-out', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from pickle import load\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    model : model that was trained on text data\n",
    "    tokenizer : tokenizer that was fit on text data\n",
    "    seq_len : length of training sequence\n",
    "    seed_text : raw string text to serve as the seed\n",
    "    num_gen_words : number of words to be generated by model\n",
    "    '''\n",
    "    \n",
    "    # Final Output\n",
    "    output_text = []\n",
    "    \n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        # Pad sequences to our trained rate (50 words in the video)\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        # Predict class probabilities for each word\n",
    "        pred_probabilities = model.predict(pad_encoded, verbose=0)[0]\n",
    "\n",
    "        # Get the index of the word with the highest probability\n",
    "        pred_word_ind = np.argmax(pred_probabilities)\n",
    "        \n",
    "        # Grab word\n",
    "        pred_word = tokenizer.index_word[pred_word_ind] \n",
    "        \n",
    "        # Update the sequence of input text (shifting one over with the new word)\n",
    "        input_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    # Make it look like a sentence.\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 08:28:00.416074: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-31 08:28:00.416683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-31 08:28:00.417400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-31 08:28:00.500557: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-31 08:28:00.501287: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-31 08:28:00.501869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-31 08:28:00.659393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-31 08:28:00.660158: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-31 08:28:00.660771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-31 08:28:00.751183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-31 08:28:00.751997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-31 08:28:00.752609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LJV MN DKTJB WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ> WLTWNJ>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "seed_text = \"DNTL LK >R<> DMRDJ> XLB> WDBC> CM< >JSRJL MRJ> >LHN MRJ> XD HW RXM LMRJ> >LHK MN KLH LBK WMN KLH^ NPCK WMN KLH QNJNK\"\n",
    "\n",
    "len(seed_text.split())\n",
    "model = load_model('s2-out.h5')\n",
    "tokenizer = load(open('s2-out', 'rb'))\n",
    "\n",
    "generate_text(model,tokenizer,seq_len=25,seed_text=seed_text,num_gen_words=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
